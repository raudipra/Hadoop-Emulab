17/08/18 01:25:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/08/18 01:25:25 INFO client.RMProxy: Connecting to ResourceManager at node-1/10.1.1.3:8032
Max number of map tasks 150
Max number of red tasks 30
shuffleInputRatio  = 0.0014809811
outputShuffleRatio = 0.012263664
Running on 15 nodes with 135 maps and 1 reduces.
0.14290283388252045
0.2999850739236041
Job started: Fri Aug 18 01:25:26 MDT 2017
17/08/18 01:25:26 INFO client.RMProxy: Connecting to ResourceManager at node-1/10.1.1.3:8032
17/08/18 01:25:26 INFO client.RMProxy: Connecting to ResourceManager at node-1/10.1.1.3:8032
17/08/18 01:25:26 INFO mapred.FileInputFormat: Total input paths to process : 7
17/08/18 01:25:27 INFO mapreduce.JobSubmitter: number of splits:14
17/08/18 01:25:27 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1503040466680_0054
17/08/18 01:25:27 INFO impl.YarnClientImpl: Submitted application application_1503040466680_0054
17/08/18 01:25:28 INFO mapreduce.Job: The url to track the job: http://node-1:8088/proxy/application_1503040466680_0054/
17/08/18 01:25:28 INFO mapreduce.Job: Running job: job_1503040466680_0054
17/08/18 01:26:11 INFO mapreduce.Job: Job job_1503040466680_0054 running in uber mode : false
17/08/18 01:26:11 INFO mapreduce.Job:  map 0% reduce 0%
17/08/18 01:26:18 INFO mapreduce.Job:  map 29% reduce 0%
17/08/18 01:26:19 INFO mapreduce.Job:  map 50% reduce 0%
17/08/18 01:26:21 INFO mapreduce.Job:  map 64% reduce 0%
17/08/18 01:26:22 INFO mapreduce.Job:  map 100% reduce 0%
17/08/18 01:26:26 INFO mapreduce.Job:  map 100% reduce 100%
17/08/18 01:26:26 INFO mapreduce.Job: Job job_1503040466680_0054 completed successfully
17/08/18 01:26:26 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=751526
		FILE: Number of bytes written=3273514
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=550157356
		HDFS: Number of bytes written=8644
		HDFS: Number of read operations=59
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=14
		Launched reduce tasks=1
		Data-local map tasks=12
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=102505
		Total time spent by all reduces in occupied slots (ms)=5461
		Total time spent by all map tasks (ms)=102505
		Total time spent by all reduce tasks (ms)=5461
		Total vcore-seconds taken by all map tasks=102505
		Total vcore-seconds taken by all reduce tasks=5461
		Total megabyte-seconds taken by all map tasks=104965120
		Total megabyte-seconds taken by all reduce tasks=5592064
	Map-Reduce Framework
		Map input records=4697623
		Map output records=6832
		Map output bytes=737856
		Map output materialized bytes=751604
		Input split bytes=1512
		Combine input records=0
		Combine output records=0
		Reduce input groups=6832
		Reduce shuffle bytes=751604
		Reduce input records=6832
		Reduce output records=73
		Spilled Records=13664
		Shuffled Maps =14
		Failed Shuffles=0
		Merged Map outputs=14
		GC time elapsed (ms)=2506
		CPU time spent (ms)=82910
		Physical memory (bytes) snapshot=3925065728
		Virtual memory (bytes) snapshot=13670694912
		Total committed heap usage (bytes)=2971664384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	org.apache.hadoop.examples.WorkGen$Counters
		MAP_BYTES_WRITTEN=683200
		MAP_RECORDS_WRITTEN=6832
		RED_BYTES_WRITTEN=7300
		RED_RECORDS_WRITTEN=73
	File Input Format Counters 
		Bytes Read=550155844
	File Output Format Counters 
		Bytes Written=8644
Job ended: Fri Aug 18 01:26:26 MDT 2017
The job took 60 seconds.
