17/08/18 21:27:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/08/18 21:27:15 INFO client.RMProxy: Connecting to ResourceManager at node-1/10.1.1.3:8032
Max number of map tasks 150
Max number of red tasks 30
shuffleInputRatio  = 0.0015543102
outputShuffleRatio = 0.0142207695
Running on 15 nodes with 135 maps and 1 reduces.
0.5096513515183919
0.12921592498137457
Job started: Fri Aug 18 21:27:16 MDT 2017
17/08/18 21:27:16 INFO client.RMProxy: Connecting to ResourceManager at node-1/10.1.1.3:8032
17/08/18 21:27:16 INFO client.RMProxy: Connecting to ResourceManager at node-1/10.1.1.3:8032
17/08/18 21:27:16 INFO mapred.FileInputFormat: Total input paths to process : 6
17/08/18 21:27:16 INFO mapreduce.JobSubmitter: number of splits:12
17/08/18 21:27:17 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1503112625968_0058
17/08/18 21:27:17 INFO impl.YarnClientImpl: Submitted application application_1503112625968_0058
17/08/18 21:27:17 INFO mapreduce.Job: The url to track the job: http://node-1:8088/proxy/application_1503112625968_0058/
17/08/18 21:27:17 INFO mapreduce.Job: Running job: job_1503112625968_0058
17/08/18 21:48:56 INFO mapreduce.Job: Job job_1503112625968_0058 running in uber mode : false
17/08/18 21:48:56 INFO mapreduce.Job:  map 0% reduce 0%
17/08/18 21:49:04 INFO mapreduce.Job:  map 8% reduce 0%
17/08/18 21:49:05 INFO mapreduce.Job:  map 50% reduce 0%
17/08/18 21:49:06 INFO mapreduce.Job:  map 83% reduce 0%
17/08/18 21:49:07 INFO mapreduce.Job:  map 100% reduce 0%
17/08/18 21:49:12 INFO mapreduce.Job:  map 100% reduce 100%
17/08/18 21:49:13 INFO mapreduce.Job: Job job_1503112625968_0058 completed successfully
17/08/18 21:49:13 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=704556
		FILE: Number of bytes written=2942774
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=471563448
		HDFS: Number of bytes written=10500
		HDFS: Number of read operations=51
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=12
		Launched reduce tasks=1
		Data-local map tasks=10
		Rack-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=84332
		Total time spent by all reduces in occupied slots (ms)=5159
		Total time spent by all map tasks (ms)=84332
		Total time spent by all reduce tasks (ms)=5159
		Total vcore-seconds taken by all map tasks=84332
		Total vcore-seconds taken by all reduce tasks=5159
		Total megabyte-seconds taken by all map tasks=86355968
		Total megabyte-seconds taken by all reduce tasks=5282816
	Map-Reduce Framework
		Map input records=4026534
		Map output records=6405
		Map output bytes=691740
		Map output materialized bytes=704622
		Input split bytes=1296
		Combine input records=0
		Combine output records=0
		Reduce input groups=6405
		Reduce shuffle bytes=704622
		Reduce input records=6405
		Reduce output records=89
		Spilled Records=12810
		Shuffled Maps =12
		Failed Shuffles=0
		Merged Map outputs=12
		GC time elapsed (ms)=1729
		CPU time spent (ms)=64880
		Physical memory (bytes) snapshot=3397648384
		Virtual memory (bytes) snapshot=11858767872
		Total committed heap usage (bytes)=2575302656
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	org.apache.hadoop.examples.WorkGen$Counters
		MAP_BYTES_WRITTEN=640500
		MAP_RECORDS_WRITTEN=6405
		RED_BYTES_WRITTEN=8900
		RED_RECORDS_WRITTEN=89
	File Input Format Counters 
		Bytes Read=471562152
	File Output Format Counters 
		Bytes Written=10500
Job ended: Fri Aug 18 21:49:13 MDT 2017
The job took 1317 seconds.
